{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we explored how to keep track of the conversataion history and the tokens used.\n",
    "\n",
    "In this section, we will look at how to generate a summary of the conversation so far. We can then use this summary as context for a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will create a Jinja template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "You are a helpful summariser, tracking information about a conversation in JSON format.\n",
    "Do not include an redundant information and do not hallucinate.\n",
    "Do not respond to the user, only update the summary.\n",
    "Keep the summary concise and to the point.\n",
    "You have just received a new message from the user (\"input_message\"), and the response from the assistant (\"assistant_response\").\n",
    "You will update the current summary (\"current_summary\") in JSON format according to the following schema:\n",
    "\n",
    "{{ schema }}\n",
    "\n",
    "### Current Summary ###\n",
    "\n",
    "{{ current_summary }}\n",
    "\n",
    "### User Message ###\n",
    "\n",
    "{{ input_message }}\n",
    "\n",
    "### Assistant Response ###\n",
    "\n",
    "{{ assistant_response }}\n",
    "\n",
    "### New Summary ###\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have three arguments: the schema, the current summary, and the new message. Notice that we are also using a schema for the summary, so we will also need to use a Pydantic model to define the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    first_name: str = Field(\"unknown\", description=\"The first name of the user.\")\n",
    "    last_name: str = Field(\"unknown\", description=\"The last name of the user.\")\n",
    "    unresolved_questions: list[str] = Field([], description=\"A list of questions that the user has asked that the assistant has not yet resolved.\")\n",
    "    summary: str = Field(\"unknown\", description=\"The running summary of the conversation so far. Update with the previous assistant response and the new input from the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">first_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">last_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">unresolved_questions</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mfirst_name\u001b[0m=\u001b[32m'unknown'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mlast_name\u001b[0m=\u001b[32m'unknown'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33munresolved_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33msummary\u001b[0m=\u001b[32m'unknown'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_summary = Summary()\n",
    "pprint(current_summary, expand_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from typing import Any\n",
    "\n",
    "def load_template(template_filepath: str, arguments: dict[str, Any]) -> str:\n",
    "    env = Environment(\n",
    "        loader=FileSystemLoader(searchpath='./'),\n",
    "        autoescape=select_autoescape()\n",
    "    )\n",
    "    template = env.get_template(template_filepath)\n",
    "    return template.render(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = load_template(\n",
    "    \"prompts/summary_system_prompt.jinja\",\n",
    "    {\n",
    "        \"schema\": current_summary.model_json_schema(),\n",
    "        \"current_summary\": current_summary.model_dump(),\n",
    "        \"input_message\": \"Hello, nice to meet you!\",\n",
    "        \"assistant_response\": \"Nice to meet you too! What is your name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful summariser, tracking information about a conversation in JSON format.\n",
      "Do not include an redundant information and do not hallucinate.\n",
      "Do not respond to the user, only update the summary.\n",
      "Keep the summary concise and to the point.\n",
      "You have just received a new message from the user (\"input_message\"), and the response from the assistant (\"assistant_response\").\n",
      "You will update the current summary (\"current_summary\") in JSON format according to the following schema:\n",
      "\n",
      "{'properties': {'first_name': {'default': 'unknown', 'description': 'The first name of the user.', 'title': 'First Name', 'type': 'string'}, 'last_name': {'default': 'unknown', 'description': 'The last name of the user.', 'title': 'Last Name', 'type': 'string'}, 'unresolved_questions': {'default': [], 'description': 'A list of questions that the user has asked that the assistant has not yet resolved.', 'items': {'type': 'string'}, 'title': 'Unresolved Questions', 'type': 'array'}, 'summary': {'default': 'unknown', 'description': 'The running summary of the conversation so far. Update with the previous assistant response and the new input from the user.', 'title': 'Summary', 'type': 'string'}}, 'title': 'Summary', 'type': 'object'}\n",
      "\n",
      "### Current Summary ###\n",
      "\n",
      "{'first_name': 'unknown', 'last_name': 'unknown', 'unresolved_questions': [], 'summary': 'unknown'}\n",
      "\n",
      "### User Message ###\n",
      "\n",
      "Hello, nice to meet you!\n",
      "\n",
      "### Assistant Response ###\n",
      "\n",
      "Nice to meet you too! What is your name?\n",
      "\n",
      "### New Summary ###\n"
     ]
    }
   ],
   "source": [
    "print(summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">first_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">last_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">unresolved_questions</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'What is your name?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"User greeted the assistant. Assistant responded and asked for the user's name.\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mfirst_name\u001b[0m=\u001b[32m'unknown'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mlast_name\u001b[0m=\u001b[32m'unknown'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33munresolved_questions\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'What is your name?'\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33msummary\u001b[0m=\u001b[32m\"User\u001b[0m\u001b[32m greeted the assistant. Assistant responded and asked for the user's name.\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def generate_summary(input_message: str) -> Summary:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": summary_prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    json_content = json.loads(response.choices[0].message.content)\n",
    "    current_summary = Summary(**json_content)\n",
    "    \n",
    "    return current_summary\n",
    "\n",
    "current_summary = generate_summary(summary_prompt)\n",
    "\n",
    "pprint(current_summary, expand_all=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have set the temperature to 0.0, to avoid the model being too \"creative\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How let's try another input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">first_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Garfield'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">last_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Leopard'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">unresolved_questions</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'What are you interested in learning about cats?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'User introduced themselves as Garfield Leopard and expressed interest in learning about cats. Assistant acknowledged the introduction and asked what specific topics about cats the user is interested in.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mfirst_name\u001b[0m=\u001b[32m'Garfield'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mlast_name\u001b[0m=\u001b[32m'Leopard'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33munresolved_questions\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'What are you interested in learning about cats?'\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33msummary\u001b[0m=\u001b[32m'User introduced themselves as Garfield Leopard and expressed interest in learning about cats. Assistant acknowledged the introduction and asked what specific topics about cats the user is interested in.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_prompt = load_template(\n",
    "    \"prompts/summary_system_prompt.jinja\",\n",
    "    {\n",
    "        \"schema\": current_summary.model_json_schema(),\n",
    "        \"current_summary\": current_summary.model_dump(),\n",
    "        \"input_message\": \"My name is Garfield Leopard. I am interested in learning about cats.\",\n",
    "        \"assistant_response\": \"Nice to meet you Garfield! I am also interested in learning about cats. What are you interested in learning about cats?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "current_summary = generate_summary(summary_prompt)\n",
    "\n",
    "pprint(current_summary, expand_all=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have updated the summary with the messages so far. But there is still one thing missing: we are not actually talking to anything! We are manually updating the messages with fake chatbot responses.\n",
    "\n",
    "So now, let's add another model instance to this conversation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this extension, we add a chatbot to the conversation. The prompt is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "You are a helpful assistant. You will respond to the user's message (\"input_message\") with a helpful response.\n",
    "You will also be given a running summary (\"running_summary\") of the conversation so far in JSON format.\n",
    "You can use this summary to help you answer the user's question.\n",
    "\n",
    "### Running Summary ###\n",
    "\n",
    "{{ running_summary }}\n",
    "\n",
    "### User Message ###\n",
    "\n",
    "{{ input_message }}\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to write logic to update the summary with the new messages. Let's walk through this step by step (because we know that this will make us perform better ðŸ˜„). We need to:\n",
    "1. Get the user input\n",
    "2. Get the prompt template for the chatbot\n",
    "3. Feed this into the chatbot along with the running summary\n",
    "4. Update the running summary with the new response from the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get user input\n",
    "user_input = \"I think I would like to learn about the noble jaguar. Can you tell me more about them?\"\n",
    "\n",
    "# 2. Get the prompt template for the chatbot\n",
    "chat_prompt = load_template(\n",
    "    \"prompts/bot_prompt.jinja\",\n",
    "    {\n",
    "        \"running_summary\": current_summary.model_dump(),\n",
    "        \"input_message\": user_input,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaguars are fascinating and powerful big cats native to the Americas. Here are some key facts about them:\n",
      "\n",
      "1. **Scientific Classification**: They belong to the species Panthera onca and are part of the Felidae family.\n",
      "\n",
      "2. **Habitat**: Jaguars are primarily found in rainforests, but they also inhabit savannas and grasslands. Their range extends from the southern United States to South America, particularly in the Amazon Basin.\n",
      "\n",
      "3. **Physical Characteristics**: Jaguars are known for their robust build and distinctive coat, which is usually a golden-yellow with black rosettes. They are the largest cats in the Americas and the third-largest in the world after tigers and lions.\n",
      "\n",
      "4. **Diet and Hunting**: Jaguars are carnivorous and have a varied diet that includes deer, capybaras, and even caimans. They are unique among big cats in that they often hunt by biting through the skull or shell of their prey.\n",
      "\n",
      "5. **Behavior**: They are solitary creatures and are excellent swimmers, often found near water. They are also known for their powerful jaws and stealthy hunting techniques.\n",
      "\n",
      "6. **Conservation Status**: Jaguars are currently listed as Near Threatened by the IUCN due to habitat loss and poaching. Conservation efforts are in place to protect their habitats and ensure their survival.\n",
      "\n",
      "If you have specific aspects of jaguars that you'd like to learn more about, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# 3. Feed this into the chatbot along with the running summary\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": chat_prompt}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">first_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Garfield'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">last_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Leopard'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">unresolved_questions</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'User expressed interest in learning about the noble jaguar. Assistant provided key facts about jaguars, including their classification, habitat, physical characteristics, diet, behavior, and conservation status.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mfirst_name\u001b[0m=\u001b[32m'Garfield'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mlast_name\u001b[0m=\u001b[32m'Leopard'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33munresolved_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33msummary\u001b[0m=\u001b[32m'User expressed interest in learning about the noble jaguar. Assistant provided key facts about jaguars, including their classification, habitat, physical characteristics, diet, behavior, and conservation status.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Update the running summary with the new response from the chatbot\n",
    "summary_prompt = load_template(\n",
    "    \"prompts/summary_system_prompt.jinja\",\n",
    "    {\n",
    "        \"schema\": current_summary.model_json_schema(),\n",
    "        \"current_summary\": current_summary.model_dump(),\n",
    "        \"input_message\": user_input,\n",
    "        \"assistant_response\": response.choices[0].message.content,\n",
    "    }\n",
    ")\n",
    "\n",
    "current_summary = generate_summary(summary_prompt)\n",
    "\n",
    "pprint(current_summary, expand_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a running summary of the conversation so far. Now out model is keeping track of the important information in the conversation without us having to feed in the full conversation history each time, which could cost a lot of money. In reality, we might to combine these approaches to get the best of both worlds.\n",
    "\n",
    "We can also add additional information to our `Summary` object to keep track of additional information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
